[1912.02877] Training Agents using Upside-Down Reinforcement Learning

## Download:

- [PDF](https://arxiv.org/pdf/1912.02877)

- [Other formats](https://arxiv.org/format/1912.02877)

([license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/))

### Current browse context:

cs.LG

   [< prev](https://arxiv.org/prevnext?id=1912.02877&function=prev&context=cs.LG)   |    [next >](https://arxiv.org/prevnext?id=1912.02877&function=next&context=cs.LG)

 [new](https://arxiv.org/list/cs.LG/new) | [recent](https://arxiv.org/list/cs.LG/recent) | [1912](https://arxiv.org/list/cs.LG/1912)

### Change to browse by:

 [cs](https://arxiv.org/abs/1912.02877?context=cs)
 [cs.AI](https://arxiv.org/abs/1912.02877?context=cs.AI)
 [cs.RO](https://arxiv.org/abs/1912.02877?context=cs.RO)

### References & Citations

- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:1912.02877)

[Export citation](#)

[Google Scholar](https://scholar.google.com/scholar?q=Training%20Agents%20using%20Upside-Down%20Reinforcement%20Learning%20Kumar%20arXiv%202019)

### Bookmark

[![reddit.png](../_resources/95d500b5112c356425b6536bb5ff98ea.png)](https://arxiv.org/ct?url=http%3A%2F%2Fwww.bibsonomy.org%2FBibtexHandler%3FrequTask%3Dupload%26url%3Dhttps%3A%2F%2Farxiv.org%2Fabs%2F1912.02877%26description%3DTraining+Agents+using+Upside-Down+Reinforcement+Learning&v=2e3eb003)  [![mendeley.png](../_resources/de3cc61e757eb08b657b7f1cd99d3bfe.png)](https://arxiv.org/ct?url=https%3A%2F%2Fwww.mendeley.com%2Fimport%2F%3Furl%3Dhttps%3A%2F%2Farxiv.org%2Fabs%2F1912.02877&v=4e4e086b)  [![bibsonomy.png](../_resources/5e3fdda030e545f9085dfbb311473d4d.png)](https://arxiv.org/ct?url=https%3A%2F%2Freddit.com%2Fsubmit%3Furl%3Dhttps%3A%2F%2Farxiv.org%2Fabs%2F1912.02877%26title%3DTraining+Agents+using+Upside-Down+Reinforcement+Learning&v=f57d2d69)  [![sciencewise.png](../_resources/7f3e03c97168aadb8b097c8433e66bc7.png)](https://arxiv.org/ct?url=http%3A%2F%2Fsciencewise.info%2Fbookmarks%2Fadd%3Furl%3Dhttps%3A%2F%2Farxiv.org%2Fabs%2F1912.02877&v=73fbfd80)

# Computer Science > Machine Learning

# Training Agents using Upside-Down Reinforcement Learning

[Rupesh Kumar Srivastava](https://arxiv.org/search/cs?searchtype=author&query=Srivastava%2C+R+K), [Pranav Shyam](https://arxiv.org/search/cs?searchtype=author&query=Shyam%2C+P), [Filipe Mutz](https://arxiv.org/search/cs?searchtype=author&query=Mutz%2C+F), [Wojciech Jaśkowski](https://arxiv.org/search/cs?searchtype=author&query=Ja%C5%9Bkowski%2C+W), [Jürgen Schmidhuber](https://arxiv.org/search/cs?searchtype=author&query=Schmidhuber%2C+J)

(Submitted on 5 Dec 2019)

>  Traditional Reinforcement Learning (RL) algorithms either predict rewards with value functions or maximize them using policy search. We study an alternative: Upside-Down Reinforcement Learning (Upside-Down RL or UDRL), that solves RL problems primarily using supervised learning techniques. Many of its main principles are outlined in a companion report [34]. Here we present the first concrete implementation of UDRL and demonstrate its feasibility on certain episodic learning problems. Experimental results show that its performance can be surprisingly competitive with, and even exceed that of traditional baseline algorithms developed over decades of research.

|     |     |
| --- | --- |
| Comments: | NNAISENSE Technical Report. 17 pages, 6 figures |
| Subjects: |  Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Robotics (cs.RO) |
| Cite as: | [arXiv:1912.02877](https://arxiv.org/abs/1912.02877) [cs.LG] |
|     | (or   [arXiv:1912.02877v1](https://arxiv.org/abs/1912.02877v1) [cs.LG] for this version) |

## Bibliographic data

[[Enable Bibex](#)([What is Bibex?](https://labs.arxiv.org/))]

## Submission history

From: Rupesh Kumar Srivastava [[view email](https://arxiv.org/show-email/ad4f6428/1912.02877)]

**[v1]**Thu, 5 Dec 2019 21:13:36 UTC (1,512 KB)

Comments for 1912.02877
by[Fermat's Library](https://fermatslibrary.com/librarian)

[Share**](https://fermatslibrary.com/arxiv_comments?url=https%3A%2F%2Farxiv.org%2Fabs%2F1912.02877)

There are no comments for this paper yet. Be the first to ask a question or share a comment.

[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/1912.02877) | [Disable MathJax](#) ([What is MathJax?](https://arxiv.org/help/mathjax)) [Browse v0.2.1 released 2019-04-18](https://confluence.cornell.edu/x/G5H4FQ)