[1702.08835] Deep Forest: Towards An Alternative to Deep Neural Networks

# Computer Science > Learning

# Deep Forest: Towards An Alternative to Deep Neural Networks

[Zhi-Hua Zhou](https://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1), [Ji Feng](https://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1)

(Submitted on 28 Feb 2017)

>  In this paper, we propose gcForest, a decision tree ensemble approach with performance highly competitive to deep neural networks. In contrast to deep neural networks which require great effort in hyper-parameter tuning, gcForest is much easier to train. Actually, even when gcForest is applied to different data from different domains, excellent performance can be achieved by almost same settings of hyper-parameters. The training process of gcForest is efficient and scalable. In our experiments its training time running on a PC is comparable to that of deep neural networks running with GPU facilities, and the efficiency advantage may be more apparent because gcForest is naturally apt to parallel implementation. Furthermore, in contrast to deep neural networks which require large-scale training data, gcForest can work well even when there are only small-scale training data. Moreover, as a tree-based approach, gcForest should be easier for theoretical analysis than deep neural networks.

|     |     |
| --- | --- |
| Comments: | 7 pages, 5 figures |
| Subjects: | Learning (cs.LG); Machine Learning (stat.ML) |
| CiteÂ as: | [arXiv:1702.08835](https://arxiv.org/abs/1702.08835) [cs.LG] |
|     | (or [arXiv:1702.08835v1](https://arxiv.org/abs/1702.08835v1) [cs.LG] for this version) |

## Submission history

From: Zhi-Hua Zhou [[view email](https://arxiv.org/show-email/1b45b96b/1702.08835)]

**[v1]** Tue, 28 Feb 2017 16:10:31 GMT (1414kb,D)

[Which authors of this paper are endorsers?](http://arxiv.org/auth/show-endorsers/1702.08835) | [Disable MathJax](#) ([What is MathJax?](https://arxiv.org/help/mathjax/))