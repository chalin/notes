tensorflow/text

 [Skip to content](https://github.com/tensorflow/text/blob/master/examples/intro.ipynb#start-of-content)

 [![](data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' class='octicon octicon-mark-github v-align-middle js-evernote-checked' height='32' viewBox='0 0 16 16' version='1.1' width='32' aria-hidden='true' data-evernote-id='4'%3e%3cpath fill-rule='evenodd' d='M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z' data-evernote-id='322' class='js-evernote-checked'%3e%3c/path%3e%3c/svg%3e)](https://github.com/)

   ![68747470733a2f2f7777772e74656e736f72666c6f772e6f72672f696d616765732f74665f6c6f676f5f333270782e706e67](../_resources/c108fcfc8efe134175adfc4bad4105f7.png)

 [Pull requests](https://github.com/pulls)  [Issues](https://github.com/issues)

 [Marketplace](https://github.com/marketplace)
 [Explore](https://github.com/explore)

 [  ![](data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' class='octicon octicon-bell js-evernote-checked' viewBox='0 0 14 16' version='1.1' width='14' height='16' aria-hidden='true' data-evernote-id='17'%3e%3cpath fill-rule='evenodd' d='M14 12v1H0v-1l.73-.58c.77-.77.81-2.55 1.19-4.42C2.69 3.23 6 2 6 2c0-.55.45-1 1-1s1 .45 1 1c0 0 3.39 1.23 4.16 5 .38 1.88.42 3.66 1.19 4.42l.66.58H14zm-7 4c1.11 0 2-.89 2-2H5c0 1.11.89 2 2 2z' data-evernote-id='382' class='js-evernote-checked'%3e%3c/path%3e%3c/svg%3e)You have unread notifications](https://github.com/notifications)

 ![](data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' class='octicon octicon-plus js-evernote-checked' viewBox='0 0 12 16' version='1.1' width='12' height='16' aria-hidden='true' data-evernote-id='18'%3e%3cpath fill-rule='evenodd' d='M12 9H7v5H5V9H0V7h5V2h2v5h5v2z' data-evernote-id='384' class='js-evernote-checked'%3e%3c/path%3e%3c/svg%3e)

 ![658327](../_resources/0c0ff4946703c3302d04e9f17f6773a8.jpg)

-

   ![](data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' class='octicon octicon-eye v-align-text-bottom js-evernote-checked' viewBox='0 0 16 16' version='1.1' width='16' height='16' aria-hidden='true' data-evernote-id='22'%3e%3cpath fill-rule='evenodd' d='M8.06 2C3 2 0 8 0 8s3 6 8.06 6C13 14 16 8 16 8s-3-6-7.94-6zM8 12c-2.2 0-4-1.78-4-4 0-2.2 1.8-4 4-4 2.22 0 4 1.8 4 4 0 2.22-1.78 4-4 4zm2-4c0 1.11-.89 2-2 2-1.11 0-2-.89-2-2 0-1.11.89-2 2-2 1.11 0 2 .89 2 2z' data-evernote-id='468' class='js-evernote-checked'%3e%3c/path%3e%3c/svg%3e) Watch

 [16](https://github.com/tensorflow/text/watchers)

- [175](https://github.com/tensorflow/text/stargazers)

- ![](data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' class='octicon octicon-repo-forked v-align-text-bottom js-evernote-checked' viewBox='0 0 10 16' version='1.1' width='10' height='16' aria-hidden='true' data-evernote-id='33'%3e%3cpath fill-rule='evenodd' d='M8 1a1.993 1.993 0 0 0-1 3.72V6L5 8 3 6V4.72A1.993 1.993 0 0 0 2 1a1.993 1.993 0 0 0-1 3.72V6.5l3 3v1.78A1.993 1.993 0 0 0 5 15a1.993 1.993 0 0 0 1-3.72V9.5l3-3V4.72A1.993 1.993 0 0 0 8 1zM2 4.2C1.34 4.2.8 3.65.8 3c0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2zm3 10c-.66 0-1.2-.55-1.2-1.2 0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2zm3-10c-.66 0-1.2-.55-1.2-1.2 0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2z' data-evernote-id='504' class='js-evernote-checked'%3e%3c/path%3e%3c/svg%3e) Fork

 [15](https://github.com/tensorflow/text/network/members)

#   ![](data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' class='octicon octicon-repo js-evernote-checked' viewBox='0 0 12 16' version='1.1' width='12' height='16' aria-hidden='true' data-evernote-id='35'%3e%3cpath fill-rule='evenodd' d='M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z' data-evernote-id='512' class='js-evernote-checked'%3e%3c/path%3e%3c/svg%3e)  [tensorflow](https://github.com/tensorflow)/**[text](https://github.com/tensorflow/text)**

   [![](data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' class='octicon octicon-code js-evernote-checked' viewBox='0 0 14 16' version='1.1' width='14' height='16' aria-hidden='true' data-evernote-id='36'%3e%3cpath fill-rule='evenodd' d='M9.5 3L8 4.5 11.5 8 8 11.5 9.5 13 14 8 9.5 3zm-5 0L0 8l4.5 5L6 11.5 2.5 8 6 4.5 4.5 3z' data-evernote-id='516' class='js-evernote-checked'%3e%3c/path%3e%3c/svg%3e)Code](https://github.com/tensorflow/text)      [![](data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' class='octicon octicon-issue-opened js-evernote-checked' viewBox='0 0 14 16' version='1.1' width='14' height='16' aria-hidden='true' data-evernote-id='37'%3e%3cpath fill-rule='evenodd' d='M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z' data-evernote-id='520' class='js-evernote-checked'%3e%3c/path%3e%3c/svg%3e)Issues3](https://github.com/tensorflow/text/issues)      [![](data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' class='octicon octicon-git-pull-request js-evernote-checked' viewBox='0 0 12 16' version='1.1' width='12' height='16' aria-hidden='true' data-evernote-id='38'%3e%3cpath fill-rule='evenodd' d='M11 11.28V5c-.03-.78-.34-1.47-.94-2.06C9.46 2.35 8.78 2.03 8 2H7V0L4 3l3 3V4h1c.27.02.48.11.69.31.21.2.3.42.31.69v6.28A1.993 1.993 0 0 0 10 15a1.993 1.993 0 0 0 1-3.72zm-1 2.92c-.66 0-1.2-.55-1.2-1.2 0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2zM4 3c0-1.11-.89-2-2-2a1.993 1.993 0 0 0-1 3.72v6.56A1.993 1.993 0 0 0 2 15a1.993 1.993 0 0 0 1-3.72V4.72c.59-.34 1-.98 1-1.72zm-.8 10c0 .66-.55 1.2-1.2 1.2-.65 0-1.2-.55-1.2-1.2 0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2zM2 4.2C1.34 4.2.8 3.65.8 3c0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2z' data-evernote-id='525' class='js-evernote-checked'%3e%3c/path%3e%3c/svg%3e)Pull requests2](https://github.com/tensorflow/text/pulls)    [![](data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' class='octicon octicon-project js-evernote-checked' viewBox='0 0 15 16' version='1.1' width='15' height='16' aria-hidden='true' data-evernote-id='39'%3e%3cpath fill-rule='evenodd' d='M10 12h3V2h-3v10zm-4-2h3V2H6v8zm-4 4h3V2H2v12zm-1 1h13V1H1v14zM14 0H1a1 1 0 0 0-1 1v14a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1V1a1 1 0 0 0-1-1z' data-evernote-id='529' class='js-evernote-checked'%3e%3c/path%3e%3c/svg%3e)Projects0](https://github.com/tensorflow/text/projects)  [![](data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' class='octicon octicon-book js-evernote-checked' viewBox='0 0 16 16' version='1.1' width='16' height='16' aria-hidden='true' data-evernote-id='40'%3e%3cpath fill-rule='evenodd' d='M3 5h4v1H3V5zm0 3h4V7H3v1zm0 2h4V9H3v1zm11-5h-4v1h4V5zm0 2h-4v1h4V7zm0 2h-4v1h4V9zm2-6v9c0 .55-.45 1-1 1H9.5l-1 1-1-1H2c-.55 0-1-.45-1-1V3c0-.55.45-1 1-1h5.5l1 1 1-1H15c.55 0 1 .45 1 1zm-8 .5L7.5 3H2v9h6V3.5zm7-.5H9.5l-.5.5V12h6V3z' data-evernote-id='531' class='js-evernote-checked'%3e%3c/path%3e%3c/svg%3e)Wiki](https://github.com/tensorflow/text/wiki)  [![](data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16' class='octicon js-evernote-checked' height='16px' width='16px' data-evernote-id='41'%3e %3cpath fill-rule='evenodd' clip-rule='evenodd' d='M1 2l7-2 7 2v6.02C15 12.69 9.69 16 8 16c-1.69 0-7-3.31-7-7.98V2zm1 .75L8 1l6 1.75v5.268C14 12.104 9.45 15 8 15c-1.45 0-6-2.896-6-6.982V2.75z' data-evernote-id='532' class='js-evernote-checked'%3e%3c/path%3e %3cpath d='M3 3.5L8 2v12c-1.207 0-5-2.482-5-5.985V3.5z' data-evernote-id='533' class='js-evernote-checked'%3e%3c/path%3e %3c/svg%3e)Security](https://github.com/tensorflow/text/security/advisories)  [![](data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' class='octicon octicon-graph js-evernote-checked' viewBox='0 0 16 16' version='1.1' width='16' height='16' aria-hidden='true' data-evernote-id='42'%3e%3cpath fill-rule='evenodd' d='M16 14v1H0V0h1v14h15zM5 13H3V8h2v5zm4 0H7V3h2v10zm4 0h-2V6h2v7z' data-evernote-id='534' class='js-evernote-checked'%3e%3c/path%3e%3c/svg%3e)Insights](https://github.com/tensorflow/text/pulse)

 *Branch:*  master

##   [text](https://github.com/tensorflow/text)  /  [examples](https://github.com/tensorflow/text/tree/master/examples)  /  **intro.ipynb**

 [Find file](https://github.com/tensorflow/text/find/master)   Copy path

   [![1414837](../_resources/36adc8f28d4abe6f112ee0b4581d2cea.jpg)](https://github.com/MarkDaoust)  [MarkDaoust](https://github.com/MarkDaoust)    [Remove extra <td> tag, fix "Note:"](https://github.com/tensorflow/text/commit/74dd6aeacfa28a988b100859a06c16bab34c0db4)        [74dd6ae](https://github.com/tensorflow/text/commit/74dd6aeacfa28a988b100859a06c16bab34c0db4)  2 days ago

 **2** contributors

   [![](https://avatars1.githubusercontent.com/u/34356?s=40&v=4)](https://github.com/tensorflow/text/commits/master/examples/intro.ipynb?author=broken)  [![1414837](../_resources/36adc8f28d4abe6f112ee0b4581d2cea.jpg)](https://github.com/tensorflow/text/commits/master/examples/intro.ipynb?author=MarkDaoust)

397 lines (396 sloc)  14.6 KB

 [![](data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' class='octicon octicon-code js-evernote-checked' viewBox='0 0 14 16' version='1.1' width='14' height='16' aria-hidden='true' data-evernote-id='45'%3e%3cpath fill-rule='evenodd' d='M9.5 3L8 4.5 11.5 8 8 11.5 9.5 13 14 8 9.5 3zm-5 0L0 8l4.5 5L6 11.5 2.5 8 6 4.5 4.5 3z' data-evernote-id='597' class='js-evernote-checked'%3e%3c/path%3e%3c/svg%3e)Display the source blob](https://github.com/tensorflow/text/blob/master/examples/intro.ipynb?short_path=0d5b602)  [![](data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' class='octicon octicon-file js-evernote-checked' viewBox='0 0 12 16' version='1.1' width='12' height='16' aria-hidden='true' data-evernote-id='46'%3e%3cpath fill-rule='evenodd' d='M6 5H2V4h4v1zM2 8h7V7H2v1zm0 2h7V9H2v1zm0 2h7v-1H2v1zm10-7.5V14c0 .55-.45 1-1 1H1c-.55 0-1-.45-1-1V2c0-.55.45-1 1-1h7.5L12 4.5zM11 5L8 2H1v12h10V5z' data-evernote-id='598' class='js-evernote-checked'%3e%3c/path%3e%3c/svg%3e)Display the rendered blob](https://github.com/tensorflow/text/blob/master/examples/intro.ipynb)

 [Raw](https://github.com/tensorflow/text/raw/master/examples/intro.ipynb)  [Blame](https://github.com/tensorflow/text/blame/master/examples/intro.ipynb)  [History](https://github.com/tensorflow/text/commits/master/examples/intro.ipynb)

 [![](data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' class='octicon octicon-device-desktop js-evernote-checked' viewBox='0 0 16 16' version='1.1' width='16' height='16' aria-hidden='true' data-evernote-id='47'%3e%3cpath fill-rule='evenodd' d='M15 2H1c-.55 0-1 .45-1 1v9c0 .55.45 1 1 1h5.34c-.25.61-.86 1.39-2.34 2h8c-1.48-.61-2.09-1.39-2.34-2H15c.55 0 1-.45 1-1V3c0-.55-.45-1-1-1zm0 9H1V3h14v8z' data-evernote-id='601' class='js-evernote-checked'%3e%3c/path%3e%3c/svg%3e)Open this file in GitHub Desktop](https://github.com/tensorflow/text/blob/master/examples/intro.ipynbgithub-mac://openRepo/https://github.com/tensorflow/text?branch=master&filepath=examples%2Fintro.ipynb)

##### Copyright 2018 The TensorFlow Authors.[¶](https://render.githubusercontent.com/view/ipynb?commit=bd19d503b4133d5b2f4c30b07f45b874073c10e8&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f74656e736f72666c6f772f746578742f626431396435303362343133336435623266346333306230376634356238373430373363313065382f6578616d706c65732f696e74726f2e6970796e62&nwo=tensorflow%2Ftext&path=examples%2Fintro.ipynb&repository_id=189305903&repository_type=Repository#Copyright-2018-The-TensorFlow-Authors.)

Licensed under the Apache License, Version 2.0 (the "License");
In [0]:

*#@title Licensed under the Apache License, Version 2.0 (the "License"); { display-mode: "form" }**# you may not use this file except in compliance with the License.**# You may obtain a copy of the License at**#**# https://www.apache.org/licenses/LICENSE-2.0**#**# Unless required by applicable law or agreed to in writing, software**# distributed under the License is distributed on an "AS IS" BASIS,**# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.**# See the License for the specific language governing permissions and**# limitations under the License.*

|     |     |     |     |
| --- | --- | --- | --- |
|  [![68747470733a2f2f7777772e74656e736f72666c6f772e6f72672f696d616765732f4769744875622d4d61726b2d333270782e706e67](../_resources/77375ab74becd09236d16a6efbdf00de.png)View on TensorFlow.org](https://www.tensorflow.org/beta/tutorials/tensorflow_text/intro) |  [![search-key-slash.png](../_resources/d34f7df0f2eb1399072119c3e008e66b.png)Run in Google Colab](https://colab.research.google.com/github/tensorflow/text/blob/master/examples/intro.ipynb) |  [![68747470733a2f2f7777772e74656e736f72666c6f772e6f72672f696d616765732f646f776e6c6f61645f6c6f676f5f333270782e706e67](../_resources/f87561b8bb354ef83b09a66e54f70e08.png)View source on GitHub](https://github.com/tensorflow/text/blob/master/examples/intro.ipynb) |  [![68747470733a2f2f7777772e74656e736f72666c6f772e6f72672f696d616765732f636f6c61625f6c6f676f5f333270782e706e67](../_resources/424d37328fa7be7fae434e69ffcf2a10.png)Download notebook](https://storage.googleapis.com/tensorflow_docs/examples/intro.ipynb) |

# TF.Text[¶](https://render.githubusercontent.com/view/ipynb?commit=bd19d503b4133d5b2f4c30b07f45b874073c10e8&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f74656e736f72666c6f772f746578742f626431396435303362343133336435623266346333306230376634356238373430373363313065382f6578616d706c65732f696e74726f2e6970796e62&nwo=tensorflow%2Ftext&path=examples%2Fintro.ipynb&repository_id=189305903&repository_type=Repository#TF.Text)

## Introduction[¶](https://render.githubusercontent.com/view/ipynb?commit=bd19d503b4133d5b2f4c30b07f45b874073c10e8&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f74656e736f72666c6f772f746578742f626431396435303362343133336435623266346333306230376634356238373430373363313065382f6578616d706c65732f696e74726f2e6970796e62&nwo=tensorflow%2Ftext&path=examples%2Fintro.ipynb&repository_id=189305903&repository_type=Repository#Introduction)

TensorFlow Text provides a collection of text related classes and ops ready to use with TensorFlow 2.0. The library can perform the preprocessing regularly required by text-based models, and includes other features useful for sequence modeling not provided by core TensorFlow.

The benefit of using these ops in your text preprocessing is that they are done in the TensorFlow graph. You do not need to worry about tokenization in training being different than the tokenization at inference, or managing preprocessing scripts.

## Eager Execution[¶](https://render.githubusercontent.com/view/ipynb?commit=bd19d503b4133d5b2f4c30b07f45b874073c10e8&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f74656e736f72666c6f772f746578742f626431396435303362343133336435623266346333306230376634356238373430373363313065382f6578616d706c65732f696e74726f2e6970796e62&nwo=tensorflow%2Ftext&path=examples%2Fintro.ipynb&repository_id=189305903&repository_type=Repository#Eager-Execution)

TensorFlow Text requires TensorFlow 2.0, and is fully compatible with eager mode and graph mode.

* * *

Note: On rare occassions, this import may fail looking for the TF library. Please reset the runtime and rerun the pip install above.

In [0]:

!pip  install  tensorflow-text
In [0]:

import  tensorflow  as  tfimport  tensorflow_text  as  text

## Unicode[¶](https://render.githubusercontent.com/view/ipynb?commit=bd19d503b4133d5b2f4c30b07f45b874073c10e8&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f74656e736f72666c6f772f746578742f626431396435303362343133336435623266346333306230376634356238373430373363313065382f6578616d706c65732f696e74726f2e6970796e62&nwo=tensorflow%2Ftext&path=examples%2Fintro.ipynb&repository_id=189305903&repository_type=Repository#Unicode)

Most ops expect that the strings are in UTF-8. If you're using a different encoding, you can use the core tensorflow transcode op to transcode into UTF-8. You can also use the same op to coerce your string to structurally valid UTF-8 if your input could be invalid.

In [0]:

docs  =  tf.constant([u'Everything not saved will be lost.'.encode('UTF-16-BE'),  u'Sad☹'.encode('UTF-16-BE')])utf8_docs  =  tf.strings.unicode_transcode(docs,  input_encoding='UTF-16-BE',  output_encoding='UTF-8')

## Tokenization[¶](https://render.githubusercontent.com/view/ipynb?commit=bd19d503b4133d5b2f4c30b07f45b874073c10e8&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f74656e736f72666c6f772f746578742f626431396435303362343133336435623266346333306230376634356238373430373363313065382f6578616d706c65732f696e74726f2e6970796e62&nwo=tensorflow%2Ftext&path=examples%2Fintro.ipynb&repository_id=189305903&repository_type=Repository#Tokenization)

Tokenization is the process of breaking up a string into tokens. Commonly, these tokens are words, numbers, and/or punctuation.

The main interfaces are `Tokenizer` and `TokenizerWithOffsets` which each have a single method `tokenize` and `tokenize_with_offsets` respectively. There are multiple tokenizers available now. Each of these implement `TokenizerWithOffsets` (which extends `Tokenizer`) which includes an option for getting byte offsets into the original string. This allows the caller to know the bytes in the original string the token was created from.

All of the tokenizers return RaggedTensors with the inner-most dimension of tokens mapping to the original individual strings. As a result, the resulting shape's rank is increased by one. Please review the ragged tensor guide if you are unfamiliar with them. https://www.tensorflow.org/guide/ragged_tensors

### WhitespaceTokenizer[¶](https://render.githubusercontent.com/view/ipynb?commit=bd19d503b4133d5b2f4c30b07f45b874073c10e8&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f74656e736f72666c6f772f746578742f626431396435303362343133336435623266346333306230376634356238373430373363313065382f6578616d706c65732f696e74726f2e6970796e62&nwo=tensorflow%2Ftext&path=examples%2Fintro.ipynb&repository_id=189305903&repository_type=Repository#WhitespaceTokenizer)

This is a basic tokenizer that splits UTF-8 strings on ICU defined whitespace characters (eg. space, tab, new line).

In [0]:

tokenizer  =  text.WhitespaceTokenizer()tokens  =  tokenizer.tokenize(['everything not saved will be lost.',  u'Sad☹'.encode('UTF-8')])print(tokens.to_list())

### UnicodeScriptTokenizer[¶](https://render.githubusercontent.com/view/ipynb?commit=bd19d503b4133d5b2f4c30b07f45b874073c10e8&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f74656e736f72666c6f772f746578742f626431396435303362343133336435623266346333306230376634356238373430373363313065382f6578616d706c65732f696e74726f2e6970796e62&nwo=tensorflow%2Ftext&path=examples%2Fintro.ipynb&repository_id=189305903&repository_type=Repository#UnicodeScriptTokenizer)

This tokenizer splits UTF-8 strings based on Unicode script boundaries. The script codes used correspond to International Components for Unicode (ICU) UScriptCode values. See: http://icu-project.org/apiref/icu4c/uscript_8h.html

In practice, this is similar to the `WhitespaceTokenizer` with the most apparent difference being that it will split punctuation (USCRIPT_COMMON) from language texts (eg. USCRIPT_LATIN, USCRIPT_CYRILLIC, etc) while also separating language texts from each other.

In [0]:

tokenizer  =  text.UnicodeScriptTokenizer()tokens  =  tokenizer.tokenize(['everything not saved will be lost.',  u'Sad☹'.encode('UTF-8')])print(tokens.to_list())

### Unicode split[¶](https://render.githubusercontent.com/view/ipynb?commit=bd19d503b4133d5b2f4c30b07f45b874073c10e8&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f74656e736f72666c6f772f746578742f626431396435303362343133336435623266346333306230376634356238373430373363313065382f6578616d706c65732f696e74726f2e6970796e62&nwo=tensorflow%2Ftext&path=examples%2Fintro.ipynb&repository_id=189305903&repository_type=Repository#Unicode-split)

When tokenizing languages without whitespace to segment words, it is common to just split by character, which can be accomplished using the [unicode_split](https://www.tensorflow.org/api_docs/python/tf/strings/unicode_split) op found in core.

In [0]:

tokens  =  tf.strings.unicode_split([u"仅今年前".encode('UTF-8')],  'UTF-8')print(tokens.to_list())

### Offsets[¶](https://render.githubusercontent.com/view/ipynb?commit=bd19d503b4133d5b2f4c30b07f45b874073c10e8&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f74656e736f72666c6f772f746578742f626431396435303362343133336435623266346333306230376634356238373430373363313065382f6578616d706c65732f696e74726f2e6970796e62&nwo=tensorflow%2Ftext&path=examples%2Fintro.ipynb&repository_id=189305903&repository_type=Repository#Offsets)

When tokenizing strings, it is often desired to know where in the original string the token originated from. For this reason, each tokenizer which implements `TokenizerWithOffsets` has a *tokenize_with_offsets* method that will return the byte offsets along with the tokens. The offset_starts lists the bytes in the original string each token starts at, and the offset_limits lists the bytes where each token ends.

In [0]:

tokenizer  =  text.UnicodeScriptTokenizer()(tokens,  offset_starts,  offset_limits)  =  tokenizer.tokenize_with_offsets(['everything not saved will be lost.',  u'Sad☹'.encode('UTF-8')])print(tokens.to_list())print(offset_starts.to_list())print(offset_limits.to_list())

### TF.Data Example[¶](https://render.githubusercontent.com/view/ipynb?commit=bd19d503b4133d5b2f4c30b07f45b874073c10e8&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f74656e736f72666c6f772f746578742f626431396435303362343133336435623266346333306230376634356238373430373363313065382f6578616d706c65732f696e74726f2e6970796e62&nwo=tensorflow%2Ftext&path=examples%2Fintro.ipynb&repository_id=189305903&repository_type=Repository#TF.Data-Example)

Tokenizers work as expected with the tf.data API. A simple example is provided below.

In [0]:

docs  =  tf.data.Dataset.from_tensor_slices([['Never tell me the odds.'],  ["It's a trap!"]])tokenizer  =  text.WhitespaceTokenizer()tokenized_docs  =  docs.map(lambda  x:  tokenizer.tokenize(x))iterator  =  iter(tokenized_docs)print(next(iterator).to_list())print(next(iterator).to_list())

## Other Text Ops[¶](https://render.githubusercontent.com/view/ipynb?commit=bd19d503b4133d5b2f4c30b07f45b874073c10e8&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f74656e736f72666c6f772f746578742f626431396435303362343133336435623266346333306230376634356238373430373363313065382f6578616d706c65732f696e74726f2e6970796e62&nwo=tensorflow%2Ftext&path=examples%2Fintro.ipynb&repository_id=189305903&repository_type=Repository#Other-Text-Ops)

TF.Text packages other useful preprocessing ops. We will review a couple below.

### Wordshape[¶](https://render.githubusercontent.com/view/ipynb?commit=bd19d503b4133d5b2f4c30b07f45b874073c10e8&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f74656e736f72666c6f772f746578742f626431396435303362343133336435623266346333306230376634356238373430373363313065382f6578616d706c65732f696e74726f2e6970796e62&nwo=tensorflow%2Ftext&path=examples%2Fintro.ipynb&repository_id=189305903&repository_type=Repository#Wordshape)

A common feature used in some natural language understanding models is to see if the text string has a certain property. For example, a sentence breaking model might contain features which check for word capitalization or if a punctuation character is at the end of a string.

Wordshape defines a variety of useful regular expression based helper functions for matching various relevant patterns in your input text. Here are a few examples.

In [0]:

tokenizer  =  text.WhitespaceTokenizer()tokens  =  tokenizer.tokenize(['Everything not saved will be lost.',  u'Sad☹'.encode('UTF-8')])*# Is capitalized?*f1  =  text.wordshape(tokens,  text.WordShape.HAS_TITLE_CASE)*# Are all letters uppercased?*f2  =  text.wordshape(tokens,  text.WordShape.IS_UPPERCASE)*# Does the token contain punctuation?*f3  =  text.wordshape(tokens,  text.WordShape.HAS_SOME_PUNCT_OR_SYMBOL)*# Is the token a number?*f4  =  text.wordshape(tokens,  text.WordShape.IS_NUMERIC_VALUE)print(f1.to_list())print(f2.to_list())print(f3.to_list())print(f4.to_list())

### N-grams & Sliding Window[¶](https://render.githubusercontent.com/view/ipynb?commit=bd19d503b4133d5b2f4c30b07f45b874073c10e8&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f74656e736f72666c6f772f746578742f626431396435303362343133336435623266346333306230376634356238373430373363313065382f6578616d706c65732f696e74726f2e6970796e62&nwo=tensorflow%2Ftext&path=examples%2Fintro.ipynb&repository_id=189305903&repository_type=Repository#N-grams-&-Sliding-Window)

N-grams are sequential words given a sliding window size of *n*. When combining the tokens, there are three reduction mechanisms supported. For text, you would want to use `Reduction.STRING_JOIN` which appends the strings to each other. The default separator character is a space, but this can be changed with the string_separater argument.

The other two reduction methods are most often used with numerical values, and these are `Reduction.SUM` and `Reduction.MEAN`.

In [0]:

tokenizer  =  text.WhitespaceTokenizer()tokens  =  tokenizer.tokenize(['Everything not saved will be lost.',  u'Sad☹'.encode('UTF-8')])*# Ngrams, in this case bi-gram (n = 2)*bigrams  =  text.ngrams(tokens,  2,  reduction_type=text.Reduction.STRING_JOIN)print(bigrams.to_list())

- © 2019 GitHub, Inc.

- [Terms](https://github.com/site/terms)

- [Privacy](https://github.com/site/privacy)

- [Security](https://github.com/security)

- [Status](https://githubstatus.com/)

- [Help](https://help.github.com/)

 [![](data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' height='24' class='octicon octicon-mark-github js-evernote-checked' viewBox='0 0 16 16' version='1.1' width='24' aria-hidden='true' data-evernote-id='50'%3e%3cpath fill-rule='evenodd' d='M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z' data-evernote-id='625' class='js-evernote-checked'%3e%3c/path%3e%3c/svg%3e)](https://github.com/)

- [Contact GitHub](https://github.com/contact)

- [Pricing](https://github.com/pricing)

- [API](https://developer.github.com/)

- [Training](https://training.github.com/)

- [Blog](https://github.blog/)

- [About](https://github.com/about)