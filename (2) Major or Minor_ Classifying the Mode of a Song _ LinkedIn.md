(2) Major or Minor? Classifying the Mode of a Song | LinkedIn

(2) Major or Minor? Classifying the Mode of a Song | LinkedIn
![](../_resources/0f1e6e81863689befbcd0caa3b1fb00d.png)

![](../_resources/b67795ec6c316c66f611fdb99d6b1d08.png)https://www.linkedin.com/pulse/major-minor-classifying-mode-song-alex-smith/

Major or Minor? Classifying the Mode of a Song Published on June 18, 2018 Alex Smith Follow Follow Data Scientist | Machine Learning 2 articles Like 18 Comment 2 1 Write an article For a while now, I have wanted to work with music in machine learning in one capacity or another. The day of reckoning has come. View my code (and the rest of my project) on Github . Overview: Problem and Background Going in to this project, I knew I wanted to work with music audio. After doing some research, I settled on working with raw audio files by extracting features from mp3s. I chose to work with music data because it is a type of audio that can evoke emotion in addition to thought. When I listen to music, I sometimes ask myself: Why does a particular song make me feel happy or sad? The key of a song helps determine the feeling of a song. There are two parts that make up the key, the tonic note (also known as the root note or base note), and the model (either major or minor). Going in to this project, I posed the question: Can I predict the mode?